{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinoJose/Tensorflow/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning with TensoFlow Part 1: Feature extraction"
      ],
      "metadata": {
        "id": "ssZ2kVrRNKBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we running a GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "jbpSFharN2se",
        "outputId": "4d5c037a-6d92-4a87-ef9b-294b89a21939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 14 13:20:07 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the data"
      ],
      "metadata": {
        "id": "BlpIqHNUOOUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of the food classes from Food101)\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
        "\n",
        "# Unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "dZyS0125OvjF",
        "outputId": "d54256f0-1bf8-434f-a50a-325e26b502ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-14 13:20:07--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.140.128, 108.177.15.128, 173.194.76.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.140.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   114MB/s    in 1.4s    \n",
            "\n",
            "2021-12-14 13:20:09 (114 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder?\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} and {len(filenames)} in the folder {dirpath}.\")"
      ],
      "metadata": {
        "id": "NsKrBY4APdoG",
        "outputId": "c610fd85-51cf-46aa-fd65-6cdcea56e627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 and 0 in the folder 10_food_classes_10_percent.\n",
            "There are 10 and 0 in the folder 10_food_classes_10_percent/train.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/pizza.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/ramen.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/grilled_salmon.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/sushi.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/hamburger.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/chicken_wings.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/steak.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/chicken_curry.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/ice_cream.\n",
            "There are 0 and 75 in the folder 10_food_classes_10_percent/train/fried_rice.\n",
            "There are 10 and 0 in the folder 10_food_classes_10_percent/test.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/pizza.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/ramen.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/grilled_salmon.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/sushi.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/hamburger.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/chicken_wings.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/steak.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/chicken_curry.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/ice_cream.\n",
            "There are 0 and 250 in the folder 10_food_classes_10_percent/test/fried_rice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders"
      ],
      "metadata": {
        "id": "prDcCq8MR8L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir, target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir, target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE, class_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "ebO0eKGzTYVj",
        "outputId": "323a1c2b-1a7d-4f2c-8aed-ae64bea9b79a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst our model is running)"
      ],
      "metadata": {
        "id": "ZCwNlPFBVwLy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks are extra functionalities you can add to your models to be performed during or after training. Some examples are below:\n",
        "* Tracking experiments with TensorBoard callback\n",
        "* Model checkpoint with ModelCheckpoint callback\n",
        "* Stopping a training (before it trains too long and overfits) with the EarlyStopping callback"
      ],
      "metadata": {
        "id": "HsTqe2ApXPs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "Q0bY10gKYXZn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub"
      ],
      "metadata": {
        "id": "fuP4wiSaupKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "sHeHt-5GOHLa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet 50 V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# Original: EfficientNetB0 feature vector (version 1)\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
        "\n",
        "# # New: EfficientNetB0 feature vector (version 2)\n",
        "# efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\""
      ],
      "metadata": {
        "id": "CFOhepBYOMR-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "  \n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False, # freeze the underlying patterns\n",
        "                                           name='feature_extraction_layer',\n",
        "                                           input_shape=IMAGE_SHAPE+(3,)) # define the input image shape\n",
        "  \n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "    feature_extractor_layer, # use the feature extraction layer as the base\n",
        "    layers.Dense(num_classes, activation='softmax', name='output_layer') # create our own output layer      \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Tm_CEtkWORO8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile\n",
        "resnet_model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ydLRVcAfOWNq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\", # save experiment logs here\n",
        "                                                                         experiment_name=\"resnet50V2\")]) # name of log files"
      ],
      "metadata": {
        "id": "ueLmfOZhOfIK",
        "outputId": "78cf5de1-9188-4a46-cbef-61c2ff05fc79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to tensorflow_hub/resnet50V2/20211214-132022\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 38s 1s/step - loss: 1.8931 - accuracy: 0.3773 - val_loss: 1.1838 - val_accuracy: 0.6348\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 22s 935ms/step - loss: 0.8652 - accuracy: 0.7533 - val_loss: 0.8409 - val_accuracy: 0.7324\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 22s 930ms/step - loss: 0.6124 - accuracy: 0.8293 - val_loss: 0.7740 - val_accuracy: 0.7480\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 22s 942ms/step - loss: 0.4760 - accuracy: 0.8787 - val_loss: 0.7189 - val_accuracy: 0.7644\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 22s 937ms/step - loss: 0.3831 - accuracy: 0.9067 - val_loss: 0.6935 - val_accuracy: 0.7692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create function to plot our loss curves\n"
      ],
      "metadata": {
        "id": "VkK-NnC0Opi0"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}